{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"DE_Capstone_Project.ipynb","provenance":[],"collapsed_sections":["SRuKEW1f1ipR","3f03aNB8UvVK","Q1_Y1eZLUvVL","VMOIWXivUvVO","87w_PCAhUvVM","Qpjjf4SXUvVN","AugVwsJOUvVN","m59xGKI6UvVO","_RYAYK7rUvVP"]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwnhRPJoWqaZ","executionInfo":{"status":"ok","timestamp":1609714260528,"user_tz":-660,"elapsed":1920,"user":{"displayName":"Matheus Rafagnin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7SdQPQGfQKJLgnEFVmvPHgK4a0mMq3FwqLOgPww=s64","userId":"05484539481513338815"}},"outputId":"18dc2cb8-e4af-40ae-bb42-373009b2fa0d"},"source":["# Drive Mount\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# Open directory\n","%cd /content/gdrive/My Drive/ONLINE COURSES/UDACITY/DATA ENGINEER NANO-DEGREE"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/ONLINE COURSES/UDACITY/DATA ENGINEER NANO-DEGREE\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dY-w4AnDWJG8","executionInfo":{"status":"ok","timestamp":1609714265639,"user_tz":-660,"elapsed":3245,"user":{"displayName":"Matheus Rafagnin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7SdQPQGfQKJLgnEFVmvPHgK4a0mMq3FwqLOgPww=s64","userId":"05484539481513338815"}},"outputId":"029311da-480f-4292-95b2-3b242a84498f"},"source":["# Install package(s)\n","!pip install pyspark==2.3.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pyspark==2.3.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: py4j==0.10.6 in /usr/local/lib/python3.6/dist-packages (from pyspark==2.3.0) (0.10.6)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"editable":true,"id":"ftL1ZPoVUvU7"},"source":["#Import packages\n","import pandas as pd\n","import configparser\n","\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import avg\n","from pyspark.sql import SQLContext\n","from pyspark.sql.functions import isnan, when, count, col, udf, dayofmonth, dayofweek, month, year, weekofyear\n","from pyspark.sql.functions import monotonically_increasing_id\n","from pyspark.sql.types import *\n","\n","import clean_functions\n","import create_functions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"LUhexIjvUvU8"},"source":["# Load configuration\n","config = configparser.ConfigParser()\n","config.read('config.cfg')\n","\n","os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n","os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"KVs8ejzRUvU9"},"source":["# Instantiate Spark Session\n","spark = SparkSession.builder.\\\n","    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n","    enableHiveSupport().getOrCreate()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SRuKEW1f1ipR"},"source":["## Immigration Data\n","---"]},{"cell_type":"code","metadata":{"editable":true,"id":"sQOeuIm505S6"},"source":["# read data\n","immi_dataset = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n","immigration_df = spark.read.format('com.github.saurfang.sas.spark').load(immi_datase)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"Ysqqzfjd05S7","outputId":"3fe03784-ebdb-4b7c-ec69-441e42a338a4"},"source":["# first five records\n","immigration_df.limit(5).toPandas()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cicid</th>\n","      <th>i94yr</th>\n","      <th>i94mon</th>\n","      <th>i94cit</th>\n","      <th>i94res</th>\n","      <th>i94port</th>\n","      <th>arrdate</th>\n","      <th>i94mode</th>\n","      <th>i94addr</th>\n","      <th>depdate</th>\n","      <th>...</th>\n","      <th>entdepu</th>\n","      <th>matflag</th>\n","      <th>biryear</th>\n","      <th>dtaddto</th>\n","      <th>gender</th>\n","      <th>insnum</th>\n","      <th>airline</th>\n","      <th>admnum</th>\n","      <th>fltno</th>\n","      <th>visatype</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6.0</td>\n","      <td>2016.0</td>\n","      <td>4.0</td>\n","      <td>692.0</td>\n","      <td>692.0</td>\n","      <td>XXX</td>\n","      <td>20573.0</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>U</td>\n","      <td>None</td>\n","      <td>1979.0</td>\n","      <td>10282016</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>1.897628e+09</td>\n","      <td>None</td>\n","      <td>B2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7.0</td>\n","      <td>2016.0</td>\n","      <td>4.0</td>\n","      <td>254.0</td>\n","      <td>276.0</td>\n","      <td>ATL</td>\n","      <td>20551.0</td>\n","      <td>1.0</td>\n","      <td>AL</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>Y</td>\n","      <td>None</td>\n","      <td>1991.0</td>\n","      <td>D/S</td>\n","      <td>M</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>3.736796e+09</td>\n","      <td>00296</td>\n","      <td>F1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>15.0</td>\n","      <td>2016.0</td>\n","      <td>4.0</td>\n","      <td>101.0</td>\n","      <td>101.0</td>\n","      <td>WAS</td>\n","      <td>20545.0</td>\n","      <td>1.0</td>\n","      <td>MI</td>\n","      <td>20691.0</td>\n","      <td>...</td>\n","      <td>None</td>\n","      <td>M</td>\n","      <td>1961.0</td>\n","      <td>09302016</td>\n","      <td>M</td>\n","      <td>None</td>\n","      <td>OS</td>\n","      <td>6.666432e+08</td>\n","      <td>93</td>\n","      <td>B2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>16.0</td>\n","      <td>2016.0</td>\n","      <td>4.0</td>\n","      <td>101.0</td>\n","      <td>101.0</td>\n","      <td>NYC</td>\n","      <td>20545.0</td>\n","      <td>1.0</td>\n","      <td>MA</td>\n","      <td>20567.0</td>\n","      <td>...</td>\n","      <td>None</td>\n","      <td>M</td>\n","      <td>1988.0</td>\n","      <td>09302016</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>AA</td>\n","      <td>9.246846e+10</td>\n","      <td>00199</td>\n","      <td>B2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17.0</td>\n","      <td>2016.0</td>\n","      <td>4.0</td>\n","      <td>101.0</td>\n","      <td>101.0</td>\n","      <td>NYC</td>\n","      <td>20545.0</td>\n","      <td>1.0</td>\n","      <td>MA</td>\n","      <td>20567.0</td>\n","      <td>...</td>\n","      <td>None</td>\n","      <td>M</td>\n","      <td>2012.0</td>\n","      <td>09302016</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>AA</td>\n","      <td>9.246846e+10</td>\n","      <td>00199</td>\n","      <td>B2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 28 columns</p>\n","</div>"],"text/plain":["   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n","0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n","1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n","2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n","3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n","4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n","\n","   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n","0      NaN   ...           U     None   1979.0  10282016   None   None   \n","1      NaN   ...           Y     None   1991.0       D/S      M   None   \n","2  20691.0   ...        None        M   1961.0  09302016      M   None   \n","3  20567.0   ...        None        M   1988.0  09302016   None   None   \n","4  20567.0   ...        None        M   2012.0  09302016   None   None   \n","\n","  airline        admnum  fltno visatype  \n","0    None  1.897628e+09   None       B2  \n","1    None  3.736796e+09  00296       F1  \n","2      OS  6.666432e+08     93       B2  \n","3      AA  9.246846e+10  00199       B2  \n","4      AA  9.246846e+10  00199       B2  \n","\n","[5 rows x 28 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"editable":true,"id":"b_jhD2MX05S8","outputId":"a1a4cab0-58ef-485d-95fd-c07cb0604bd7"},"source":["# number of records\n","print_formatted_float(immigration_df.count())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3,096,313\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"editable":true,"id":"DAqJ5dGi05S8","outputId":"bceba8f0-9727-4d9a-a921-eca52569c275"},"source":["# shows top 5 unique visa country codes\n","immigration_df.select(\"visapost\").dropDuplicates().show(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+--------+\n","|visapost|\n","+--------+\n","|     CRS|\n","|     KGL|\n","|     AKD|\n","|     BGM|\n","|     TRK|\n","+--------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"editable":true,"id":"TiMpF5QCUvVI"},"source":["#### Data Cleaning:\n","---\n","> Drop all columns with most N/A values. Contains unsufficient data to be used for analytics.\n","\n","> Drop all rows with N/A values. "]},{"cell_type":"markdown","metadata":{"editable":true,"id":"kuccys9IUvVJ"},"source":["###### Drop columns with significant missing values"]},{"cell_type":"code","metadata":{"editable":true,"id":"aNIZUHPHUvVJ"},"source":["# remove columns missing most values\n","columns = ['insnum', 'entdepu', 'occup']\n","cleaned_immi_df = immigration_df.drop(*columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"f21o1jsuUvVJ","outputId":"b241302d-b7c6-4916-e527-f3e4088e0c87"},"source":["# display the new schema\n","cleaned_immi_df.printSchema()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["root\n"," |-- cicid: double (nullable = true)\n"," |-- i94yr: double (nullable = true)\n"," |-- i94mon: double (nullable = true)\n"," |-- i94cit: double (nullable = true)\n"," |-- i94res: double (nullable = true)\n"," |-- i94port: string (nullable = true)\n"," |-- arrdate: double (nullable = true)\n"," |-- i94mode: double (nullable = true)\n"," |-- i94addr: string (nullable = true)\n"," |-- depdate: double (nullable = true)\n"," |-- i94bir: double (nullable = true)\n"," |-- i94visa: double (nullable = true)\n"," |-- count: double (nullable = true)\n"," |-- dtadfile: string (nullable = true)\n"," |-- visapost: string (nullable = true)\n"," |-- entdepa: string (nullable = true)\n"," |-- entdepd: string (nullable = true)\n"," |-- matflag: string (nullable = true)\n"," |-- biryear: double (nullable = true)\n"," |-- dtaddto: string (nullable = true)\n"," |-- gender: string (nullable = true)\n"," |-- airline: string (nullable = true)\n"," |-- admnum: double (nullable = true)\n"," |-- fltno: string (nullable = true)\n"," |-- visatype: string (nullable = true)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"editable":true,"id":"NOKYknquUvVJ"},"source":["# drop duplicates\n","cleaned_immi_df = cleaned_immi_df.dropDuplicates(['cicid'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"cMJYpi0TUvVJ","outputId":"a870658f-079e-4db2-86ba-28c535e3ec97"},"source":["# count after dropping duplicates\n","print_formatted_float(cleaned_immi_df.count())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3,096,313\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"editable":true,"id":"8CVs9mNKUvVJ"},"source":["# drop rows missing values\n","cleaned_immi_df = cleaned_immi_df.dropna(how='all', subset=['cicid'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"ILv8FJjdUvVJ","outputId":"e957a164-3e91-4487-bdd2-11c9668b5752"},"source":["# count after dropping rows\n","print_formatted_float(cleaned_immi_df.count())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3,096,313\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"editable":true,"id":"4FBOBbIwUvVK","outputId":"69227419-f8f0-4448-ac9a-34229ffa9d47"},"source":["# clean the immigration dataframe\n","final_immigration_df = clean_functions.clean_immigration_spark_df(immigration_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total records in dataframe: 3,096,313\n","Total records after cleaning: 3,096,313\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"editable":true,"id":"3f03aNB8UvVK"},"source":["## World Temperature Data\n","---"]},{"cell_type":"code","metadata":{"id":"y9GOhspM3Ra5"},"source":["# load dataset\n","temp_dataset = '../../data2/GlobalLandTemperaturesByCity.csv'\n","temperature_df = spark.read.csv(temp_dataset, header=True, inferSchema=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"Ud4_HN0MUvVK","outputId":"cfc7b13c-cefc-401d-a7ec-6952fbf3ae1e"},"source":["# schema\n","temperature_df.printSchema()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["root\n"," |-- dt: timestamp (nullable = true)\n"," |-- AverageTemperature: double (nullable = true)\n"," |-- AverageTemperatureUncertainty: double (nullable = true)\n"," |-- City: string (nullable = true)\n"," |-- Country: string (nullable = true)\n"," |-- Latitude: string (nullable = true)\n"," |-- Longitude: string (nullable = true)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"editable":true,"id":"0r2XW-fcUvVK"},"source":["#### Data Cleaning:\n","\n","-  Drop all rows with N/A in average temperature\n","-  Drop duplicate columns "]},{"cell_type":"code","metadata":{"editable":true,"id":"WZyCfNUdUvVK","outputId":"edb506a8-afad-4546-f677-36e314cdc774"},"source":["# clean the data\n","cleaned_temp_df = clean_functions.clean_temperature_spark_df(temperature_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total records in dataframe: 8,599,212\n","Total records after dropping rows with missing values: 364,130\n","Rows dropped after accounting for duplicates: 44,299\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"editable":true,"id":"Q1_Y1eZLUvVL"},"source":["## Demographics Data \n","---"]},{"cell_type":"code","metadata":{"editable":true,"id":"U39smh3p05TG"},"source":["# load dataset\n","demo_dataset = \"us-cities-demographics.csv\"\n","demographics_df = spark.read.csv(demo_dataset, inferSchema=True, header=True, sep=';')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"o_fau1PM05TG","outputId":"826237a8-f0c8-4721-a8a0-1e71c7118459"},"source":["# first 5 rows\n","demographics_df.limit(5).toPandas()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Median Age</th>\n","      <th>Male Population</th>\n","      <th>Female Population</th>\n","      <th>Total Population</th>\n","      <th>Number of Veterans</th>\n","      <th>Foreign-born</th>\n","      <th>Average Household Size</th>\n","      <th>State Code</th>\n","      <th>Race</th>\n","      <th>Count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Silver Spring</td>\n","      <td>Maryland</td>\n","      <td>33.8</td>\n","      <td>40601</td>\n","      <td>41862</td>\n","      <td>82463</td>\n","      <td>1562</td>\n","      <td>30908</td>\n","      <td>2.60</td>\n","      <td>MD</td>\n","      <td>Hispanic or Latino</td>\n","      <td>25924</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Quincy</td>\n","      <td>Massachusetts</td>\n","      <td>41.0</td>\n","      <td>44129</td>\n","      <td>49500</td>\n","      <td>93629</td>\n","      <td>4147</td>\n","      <td>32935</td>\n","      <td>2.39</td>\n","      <td>MA</td>\n","      <td>White</td>\n","      <td>58723</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hoover</td>\n","      <td>Alabama</td>\n","      <td>38.5</td>\n","      <td>38040</td>\n","      <td>46799</td>\n","      <td>84839</td>\n","      <td>4819</td>\n","      <td>8229</td>\n","      <td>2.58</td>\n","      <td>AL</td>\n","      <td>Asian</td>\n","      <td>4759</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Rancho Cucamonga</td>\n","      <td>California</td>\n","      <td>34.5</td>\n","      <td>88127</td>\n","      <td>87105</td>\n","      <td>175232</td>\n","      <td>5821</td>\n","      <td>33878</td>\n","      <td>3.18</td>\n","      <td>CA</td>\n","      <td>Black or African-American</td>\n","      <td>24437</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Newark</td>\n","      <td>New Jersey</td>\n","      <td>34.6</td>\n","      <td>138040</td>\n","      <td>143873</td>\n","      <td>281913</td>\n","      <td>5829</td>\n","      <td>86253</td>\n","      <td>2.73</td>\n","      <td>NJ</td>\n","      <td>White</td>\n","      <td>76402</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               City          State  Median Age  Male Population  \\\n","0     Silver Spring       Maryland        33.8            40601   \n","1            Quincy  Massachusetts        41.0            44129   \n","2            Hoover        Alabama        38.5            38040   \n","3  Rancho Cucamonga     California        34.5            88127   \n","4            Newark     New Jersey        34.6           138040   \n","\n","   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n","0              41862             82463                1562         30908   \n","1              49500             93629                4147         32935   \n","2              46799             84839                4819          8229   \n","3              87105            175232                5821         33878   \n","4             143873            281913                5829         86253   \n","\n","   Average Household Size State Code                       Race  Count  \n","0                    2.60         MD         Hispanic or Latino  25924  \n","1                    2.39         MA                      White  58723  \n","2                    2.58         AL                      Asian   4759  \n","3                    3.18         CA  Black or African-American  24437  \n","4                    2.73         NJ                      White  76402  "]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"editable":true,"id":"6n2yCK-sUvVL","outputId":"5d4c5d3c-b9df-4bc4-fcbc-6309148754c7"},"source":["# number of records\n","print_formatted_float(demographics_df.count())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2,891\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"editable":true,"id":"vM9h2lbcUvVL","outputId":"d368dff3-a121-421e-e636-8e9a9ac19ee9"},"source":["# schema\n","demographics_df.printSchema()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["root\n"," |-- City: string (nullable = true)\n"," |-- State: string (nullable = true)\n"," |-- Median Age: double (nullable = true)\n"," |-- Male Population: integer (nullable = true)\n"," |-- Female Population: integer (nullable = true)\n"," |-- Total Population: integer (nullable = true)\n"," |-- Number of Veterans: integer (nullable = true)\n"," |-- Foreign-born: integer (nullable = true)\n"," |-- Average Household Size: double (nullable = true)\n"," |-- State Code: string (nullable = true)\n"," |-- Race: string (nullable = true)\n"," |-- Count: integer (nullable = true)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"editable":true,"id":"lel54vrvUvVM"},"source":["#### Data Cleaning:\n","\n","-  Drop rows with N/A values\n","-  Drop duplicate columns "]},{"cell_type":"code","metadata":{"editable":true,"id":"PPY4GiqOUvVM","outputId":"b47e66c3-40a1-46c8-c393-496fbd77fa1d"},"source":["# clean demographics data\n","cleaned_demographics_df = clean_functions.clean_demographics_spark_df(demographics_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Rows dropped with missing values: 16\n","Rows dropped after accounting for duplicates: 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"editable":true,"id":"irJ36-UNUvVM"},"source":["# Pipelines - Model Data"]},{"cell_type":"markdown","metadata":{"editable":true,"id":"VMOIWXivUvVO"},"source":["##### Create the immigration fact table\n","---"]},{"cell_type":"code","metadata":{"editable":true,"id":"upfzVMaOUvVO"},"source":["def create_immigration_fact_table(spark, df, output_data):\n","    \"\"\"\n","      Creates country dimension from immigration and land temperatures datasets.\n","    \"\"\"\n","\n","    # retrieve visa_type dimension\n","    dim_df = retrieve_visa_type_dim(spark, output_data)\n","\n","    # create/replace view for visa type\n","    dim_df.createOrReplaceTempView(\"visa_type_view\")\n","\n","    # udf that converts SAS format to datetime\n","    get_datetime = udf(lambda x: (dt.datetime(1960, 1, 1).date() + dt.timedelta(x)).isoformat() if x else None)\n","\n","    # rename columns\n","    df = df.withColumnRenamed('ccid', 'record_id') \\\n","           .withColumnRenamed('i94res', 'residence_code') \\\n","           .withColumnRenamed('i94addr', 'state_code')\n","\n","    # create/replace view for immigration\n","    df.createOrReplaceTempView(\"immigration_view\")\n","\n","    # create visa_type key\n","    df = spark.sql(\n","        \"\"\"\n","        SELECT \n","            immigration_view.*, \n","            visa_type_view.visa_type_id\n","        FROM immigration_view\n","        LEFT JOIN visa_type_view ON visa_type_view.visatype=immigration_view.visatype\n","        \"\"\"\n","    )\n","\n","    # converts date into datetime object\n","    df = df.withColumn(\"arrdate\", get_datetime(df.arrdate))\n","\n","    # drop visatype key\n","    df = df.drop(df.visatype)\n","\n","    # write/overwrite dimension to parquet\n","    df.write.parquet(output_data + \"immigration_fact\", mode=\"overwrite\")\n","\n","    return immigration_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"K_OqbeP_UvVO"},"source":["immigration_df = create_immigration_fact_table(final_immigration_df, output_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"editable":true,"id":"87w_PCAhUvVM"},"source":["##### Create immigration arrivals table\n","---"]},{"cell_type":"code","metadata":{"editable":true,"id":"-Hg8dxmsUvVM"},"source":["def create_immigration_arrivals_dimension(df, output_data):\n","    \"\"\"\n","      Creates immigration arrivals table\n","    \"\"\"\n","\n","    # udf that converts SAS format to datetime\n","    get_datetime = udf(lambda x: (dt.datetime(1960, 1, 1).date() + dt.timedelta(x)).isoformat() if x else None)\n","\n","    arrivals_df = df.select(['arrdate']).withColumn(\"arrdate\", get_datetime(df.arrdate)).distinct()\n","\n","    # compartmentalize datetime data\n","    arrivals_df = arrivals_df.withColumn('arrival_day', dayofmonth('arrdate'))\n","    arrivals_df = arrivals_df.withColumn('arrival_week', weekofyear('arrdate'))\n","    arrivals_df = arrivals_df.withColumn('arrival_month', month('arrdate'))\n","    arrivals_df = arrivals_df.withColumn('arrival_year', year('arrdate'))\n","    arrivals_df = arrivals_df.withColumn('arrival_weekday', dayofweek('arrdate'))\n","\n","    # create id field\n","    arrivals_df = arrivals_df.withColumn('id', monotonically_increasing_id())\n","\n","    # write/overwrite dimension to parquet\n","    part_columns = ['arrival_year', 'arrival_month', 'arrival_week']\n","    arrivals_df.write.parquet(output_data + \"immigration_arrivals\", partitionBy=part_columns, mode=\"overwrite\")\n","\n","    return arrivals_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YsMxqNm1-YP8"},"source":["output_data = \"tables/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"-wmDlHD6UvVN"},"source":["arrivals_df = create_immigration_arrivals_dimension(final_immigration_df, output_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"editable":true,"id":"Qpjjf4SXUvVN"},"source":["##### Create the visa type dimension table\n","---"]},{"cell_type":"code","metadata":{"editable":true,"id":"R-K7OLsdUvVN"},"source":["def create_visa_dimension_table(df, output_data):\n","    \"\"\"\n","      Creates visa dimension from immigration dataset.\n","    \n","    \"\"\"\n","    # create visa type df\n","    visatype_df = df.select(['visatype']).distinct()\n","\n","    # add id column\n","    visatype_df = visatype_df.withColumn('visa_type_id', monotonically_increasing_id())\n","\n","    # write/overwrite dimension to parquet\n","    visatype_df.write.parquet(output_data + \"visatype\", mode=\"overwrite\")\n","\n","    return visatype_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"_MQVcNmNUvVN","outputId":"5950a53e-b425-4f6c-9899-da0fcdb1f018"},"source":["# test create visa_type dimension function\n","visatype_df = create_visa_dimension_table(final_immigration_df, output_data)\n","visatype_df.show(n=5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+--------+-------------+\n","|visatype|visa_type_key|\n","+--------+-------------+\n","|      F2| 103079215104|\n","|     GMB| 352187318272|\n","|      B2| 369367187456|\n","|      F1| 498216206336|\n","|     CPL| 601295421440|\n","+--------+-------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"editable":true,"id":"AugVwsJOUvVN"},"source":["##### Create country table\n","---"]},{"cell_type":"code","metadata":{"editable":true,"id":"T3wRbi5zUvVN"},"source":["def create_country_dimension_table(spark, df, temp_df, output_data, mapping_file):\n","    \"\"\"\n","      Creates country dimension table.\n","    \"\"\"\n","\n","    # create/replace view for immigration\n","    df.createOrReplaceTempView(\"immigration_view\")\n","\n","    # create/replace view for countries codes\n","    mapping_file.createOrReplaceTempView(\"country_codes_view\")\n","\n","    # retreive grouped temperature data\n","    agg_temp = group_temperature_data(temp_df)\n","\n","    # create/replace view for countries temperature\n","    agg_temp.createOrReplaceTempView(\"grouped_temperature_view\")\n","\n","    # create country dimension using SQL\n","    country_df = spark.sql(\n","        \"\"\"\n","        SELECT \n","            i94res as country_code,\n","            Name as country_name\n","        FROM immigration_view\n","        LEFT JOIN country_codes_view\n","        ON immigration_view.i94res=country_codes_view.code\n","        \"\"\"\n","    ).distinct()\n","\n","    # create temp country view\n","    country_df.createOrReplaceTempView(\"country_view\")\n","\n","    country_df = spark.sql(\n","        \"\"\"\n","        SELECT \n","            country_code,\n","            country_name,\n","            average_temperature\n","        FROM country_view\n","        LEFT JOIN grouped_temperature_view\n","        ON country_view.country_name=grouped_temperature_view.Country\n","        \"\"\"\n","    ).distinct()\n","\n","    # write/overwrite dimension to a parquet\n","    country_df.write.parquet(output_data + \"country\", mode=\"overwrite\")\n","\n","    return country_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"r-XIWM5aUvVN"},"source":["country_df = create_country_dimension_table(new_immigration_df, new_temperature_df, output_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"ItnMloETUvVN","outputId":"1cdadc60-d7d7-456b-bb63-586a93e457f6"},"source":["country_dim_f.show(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+------------+------------+-------------------+\n","|country_code|country_name|average_temperature|\n","+------------+------------+-------------------+\n","|       692.0|     Ecuador|      20.5391705374|\n","|       299.0|    Mongolia|     -3.36548531952|\n","|       576.0| El Salvador|      25.2628525509|\n","|       735.0|  Montenegro|      10.2210401137|\n","|       206.0|   Hong Kong|      21.4236961538|\n","+------------+------------+-------------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"editable":true,"id":"m59xGKI6UvVO"},"source":["##### Create the demographics dimension table\n","---"]},{"cell_type":"code","metadata":{"editable":true,"id":"kXc6-UwFUvVO"},"source":["def create_demographics_dimension_table(df, output_data):\n","    \"\"\"\n","      Creates demographics dimension table.\n","    \"\"\"\n","\n","    dim_df = df.withColumnRenamed('Median Age', 'median_age') \\\n","                .withColumnRenamed('Male Population', 'male_population') \\\n","                .withColumnRenamed('Female Population', 'female_population') \\\n","                .withColumnRenamed('Total Population', 'total_population') \\\n","                .withColumnRenamed('Number of Veterans', 'number_of_veterans') \\\n","                .withColumnRenamed('Foreign-born', 'foreign_born') \\\n","                .withColumnRenamed('Average Household Size', 'average_household_size') \\\n","                .withColumnRenamed('State Code', 'state_code')\n","\n","    # add id column\n","    dim_df = dim_df.withColumn('id', monotonically_increasing_id())\n","\n","    # write/overwrite dimension to parquet\n","    dim_df.write.parquet(output_data + \"demographics\", mode=\"overwrite\")\n","\n","    return demographics_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"editable":true,"id":"RX-jPrCNUvVO","outputId":"64ec0c43-4592-4b6a-c401-671543eb1071"},"source":["demographics_df = create_demographics_dimension_table(demographics_df, output_data)\n","demographics_df.limit(5).toPandas()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>median_age</th>\n","      <th>male_population</th>\n","      <th>female_population</th>\n","      <th>total_population</th>\n","      <th>number_of_veterans</th>\n","      <th>foreign_born</th>\n","      <th>average_household_size</th>\n","      <th>state_code</th>\n","      <th>Race</th>\n","      <th>Count</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Quincy</td>\n","      <td>Massachusetts</td>\n","      <td>41.0</td>\n","      <td>44129</td>\n","      <td>49500</td>\n","      <td>93629</td>\n","      <td>4147</td>\n","      <td>32935</td>\n","      <td>2.39</td>\n","      <td>MA</td>\n","      <td>White</td>\n","      <td>58723</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Wilmington</td>\n","      <td>North Carolina</td>\n","      <td>35.5</td>\n","      <td>52346</td>\n","      <td>63601</td>\n","      <td>115947</td>\n","      <td>5908</td>\n","      <td>7401</td>\n","      <td>2.24</td>\n","      <td>NC</td>\n","      <td>Asian</td>\n","      <td>3152</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Tampa</td>\n","      <td>Florida</td>\n","      <td>35.3</td>\n","      <td>175517</td>\n","      <td>193511</td>\n","      <td>369028</td>\n","      <td>20636</td>\n","      <td>58795</td>\n","      <td>2.47</td>\n","      <td>FL</td>\n","      <td>Hispanic or Latino</td>\n","      <td>95154</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Gastonia</td>\n","      <td>North Carolina</td>\n","      <td>36.9</td>\n","      <td>35527</td>\n","      <td>39023</td>\n","      <td>74550</td>\n","      <td>3537</td>\n","      <td>5715</td>\n","      <td>2.67</td>\n","      <td>NC</td>\n","      <td>Asian</td>\n","      <td>2788</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tyler</td>\n","      <td>Texas</td>\n","      <td>33.9</td>\n","      <td>50422</td>\n","      <td>53283</td>\n","      <td>103705</td>\n","      <td>4813</td>\n","      <td>8225</td>\n","      <td>2.59</td>\n","      <td>TX</td>\n","      <td>American Indian and Alaska Native</td>\n","      <td>1057</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         City           State  median_age  male_population  female_population  \\\n","0      Quincy   Massachusetts        41.0            44129              49500   \n","1  Wilmington  North Carolina        35.5            52346              63601   \n","2       Tampa         Florida        35.3           175517             193511   \n","3    Gastonia  North Carolina        36.9            35527              39023   \n","4       Tyler           Texas        33.9            50422              53283   \n","\n","   total_population  number_of_veterans  foreign_born  average_household_size  \\\n","0             93629                4147         32935                    2.39   \n","1            115947                5908          7401                    2.24   \n","2            369028               20636         58795                    2.47   \n","3             74550                3537          5715                    2.67   \n","4            103705                4813          8225                    2.59   \n","\n","  state_code                               Race  Count  id  \n","0         MA                              White  58723   0  \n","1         NC                              Asian   3152   1  \n","2         FL                 Hispanic or Latino  95154   2  \n","3         NC                              Asian   2788   3  \n","4         TX  American Indian and Alaska Native   1057   4  "]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"editable":true,"id":"_RYAYK7rUvVP"},"source":["#### 4.2 Data Quality Checks\n","The data quality checks ensures that the ETL has created fact and dimension tables with adequate records. "]},{"cell_type":"code","metadata":{"editable":true,"id":"OC_eLWLTUvVP"},"source":["tables = {\n","    'immigration_fact': immigration_df,\n","    'visatype': visatype_df,\n","    'immigration_arrivals': arrivals_df,\n","    'demographics': demographics_df,\n","    'country': country_df\n","}\n","for table_name, table_df in tables.items():\n","    create_functions.data_quality_check(table_df, table_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AkMpWPsW7BlA"},"source":["Quality check Successful on immigration_fact - 3,096,313 records. \\\n","Quality check Successful on visatype - 17 records. \\\n","Quality check Successful on immigration_arrivals - 30 records. \\\n","Quality check Successful on demographics - 2,875 records. \\\n","Quality check Successful on country - 229 records. \\"]},{"cell_type":"code","metadata":{"id":"OunoJQRx7B_v"},"source":[""],"execution_count":null,"outputs":[]}]}